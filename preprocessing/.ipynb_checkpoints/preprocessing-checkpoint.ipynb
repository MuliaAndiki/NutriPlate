{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "dc0811e1-b9fb-43af-ba0d-b6d766a14e80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ultralytics in ./yolov_env/lib/python3.12/site-packages (8.3.236)\n",
      "Requirement already satisfied: numpy>=1.23.0 in ./yolov_env/lib/python3.12/site-packages (from ultralytics) (2.2.6)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in ./yolov_env/lib/python3.12/site-packages (from ultralytics) (3.10.8)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in ./yolov_env/lib/python3.12/site-packages (from ultralytics) (4.12.0.88)\n",
      "Requirement already satisfied: pillow>=7.1.2 in ./yolov_env/lib/python3.12/site-packages (from ultralytics) (11.3.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in ./yolov_env/lib/python3.12/site-packages (from ultralytics) (6.0.3)\n",
      "Requirement already satisfied: requests>=2.23.0 in ./yolov_env/lib/python3.12/site-packages (from ultralytics) (2.32.5)\n",
      "Requirement already satisfied: scipy>=1.4.1 in ./yolov_env/lib/python3.12/site-packages (from ultralytics) (1.16.3)\n",
      "Requirement already satisfied: torch>=1.8.0 in ./yolov_env/lib/python3.12/site-packages (from ultralytics) (2.7.1+cu118)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in ./yolov_env/lib/python3.12/site-packages (from ultralytics) (0.22.1+cu118)\n",
      "Requirement already satisfied: psutil>=5.8.0 in ./yolov_env/lib/python3.12/site-packages (from ultralytics) (7.1.3)\n",
      "Requirement already satisfied: polars>=0.20.0 in ./yolov_env/lib/python3.12/site-packages (from ultralytics) (1.36.1)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.18 in ./yolov_env/lib/python3.12/site-packages (from ultralytics) (2.0.18)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./yolov_env/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in ./yolov_env/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./yolov_env/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (4.61.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./yolov_env/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in ./yolov_env/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n",
      "Requirement already satisfied: pyparsing>=3 in ./yolov_env/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./yolov_env/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
      "Requirement already satisfied: polars-runtime-32==1.36.1 in ./yolov_env/lib/python3.12/site-packages (from polars>=0.20.0->ultralytics) (1.36.1)\n",
      "Requirement already satisfied: six>=1.5 in ./yolov_env/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./yolov_env/lib/python3.12/site-packages (from requests>=2.23.0->ultralytics) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./yolov_env/lib/python3.12/site-packages (from requests>=2.23.0->ultralytics) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./yolov_env/lib/python3.12/site-packages (from requests>=2.23.0->ultralytics) (2.6.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./yolov_env/lib/python3.12/site-packages (from requests>=2.23.0->ultralytics) (2025.11.12)\n",
      "Requirement already satisfied: filelock in ./yolov_env/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in ./yolov_env/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (4.15.0)\n",
      "Requirement already satisfied: setuptools in ./yolov_env/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (70.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in ./yolov_env/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (1.14.0)\n",
      "Requirement already satisfied: networkx in ./yolov_env/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (3.5)\n",
      "Requirement already satisfied: jinja2 in ./yolov_env/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
      "Requirement already satisfied: fsspec in ./yolov_env/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (2025.9.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.8.89 in ./yolov_env/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (11.8.89)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.8.89 in ./yolov_env/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (11.8.89)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.8.87 in ./yolov_env/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (11.8.87)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==9.1.0.70 in ./yolov_env/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.11.3.6 in ./yolov_env/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (11.11.3.6)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in ./yolov_env/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.3.0.86 in ./yolov_env/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (10.3.0.86)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.1.48 in ./yolov_env/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (11.4.1.48)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.5.86 in ./yolov_env/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (11.7.5.86)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.21.5 in ./yolov_env/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.8.86 in ./yolov_env/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (11.8.86)\n",
      "Requirement already satisfied: triton==3.3.1 in ./yolov_env/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (3.3.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./yolov_env/lib/python3.12/site-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./yolov_env/lib/python3.12/site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n",
      "Requirement already satisfied: opencv-python-headless in ./yolov_env/lib/python3.12/site-packages (4.12.0.88)\n",
      "Requirement already satisfied: numpy<2.3.0,>=2 in ./yolov_env/lib/python3.12/site-packages (from opencv-python-headless) (2.2.6)\n",
      "Requirement already satisfied: albumentations in ./yolov_env/lib/python3.12/site-packages (2.0.8)\n",
      "Requirement already satisfied: numpy>=1.24.4 in ./yolov_env/lib/python3.12/site-packages (from albumentations) (2.2.6)\n",
      "Requirement already satisfied: scipy>=1.10.0 in ./yolov_env/lib/python3.12/site-packages (from albumentations) (1.16.3)\n",
      "Requirement already satisfied: PyYAML in ./yolov_env/lib/python3.12/site-packages (from albumentations) (6.0.3)\n",
      "Requirement already satisfied: pydantic>=2.9.2 in ./yolov_env/lib/python3.12/site-packages (from albumentations) (2.12.5)\n",
      "Requirement already satisfied: albucore==0.0.24 in ./yolov_env/lib/python3.12/site-packages (from albumentations) (0.0.24)\n",
      "Requirement already satisfied: opencv-python-headless>=4.9.0.80 in ./yolov_env/lib/python3.12/site-packages (from albumentations) (4.12.0.88)\n",
      "Requirement already satisfied: stringzilla>=3.10.4 in ./yolov_env/lib/python3.12/site-packages (from albucore==0.0.24->albumentations) (4.4.0)\n",
      "Requirement already satisfied: simsimd>=5.9.2 in ./yolov_env/lib/python3.12/site-packages (from albucore==0.0.24->albumentations) (6.5.3)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./yolov_env/lib/python3.12/site-packages (from pydantic>=2.9.2->albumentations) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in ./yolov_env/lib/python3.12/site-packages (from pydantic>=2.9.2->albumentations) (2.41.5)\n",
      "Requirement already satisfied: typing-extensions>=4.14.1 in ./yolov_env/lib/python3.12/site-packages (from pydantic>=2.9.2->albumentations) (4.15.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in ./yolov_env/lib/python3.12/site-packages (from pydantic>=2.9.2->albumentations) (0.4.2)\n",
      "Requirement already satisfied: labelImg in ./yolov_env/lib/python3.12/site-packages (1.8.6)\n",
      "Requirement already satisfied: pyqt5 in ./yolov_env/lib/python3.12/site-packages (from labelImg) (5.15.11)\n",
      "Requirement already satisfied: lxml in ./yolov_env/lib/python3.12/site-packages (from labelImg) (6.0.2)\n",
      "Requirement already satisfied: PyQt5-sip<13,>=12.15 in ./yolov_env/lib/python3.12/site-packages (from pyqt5->labelImg) (12.17.2)\n",
      "Requirement already satisfied: PyQt5-Qt5<5.16.0,>=5.15.2 in ./yolov_env/lib/python3.12/site-packages (from pyqt5->labelImg) (5.15.18)\n"
     ]
    }
   ],
   "source": [
    "!pip install ultralytics\n",
    "!pip install opencv-python-headless\n",
    "!pip install albumentations\n",
    "!pip install labelImg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "39879989-2792-4d5f-acc5-c9930633b1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from ultralytics import YOLO\n",
    "import os\n",
    "import glob\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5009fc05-1b01-4f15-984a-fed7151dc245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA: True\n",
      "GPU: NVIDIA GeForce RTX 3050 6GB Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "print(\"CUDA:\", torch.cuda.is_available())\n",
    "print(\"GPU:\", torch.cuda.get_device_name(0))\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ede7f5ce-a096-4b69-af0f-f5a69644f758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. üóëÔ∏è MENGHAPUS CACHE...\n",
      "\n",
      "2. üìÅ CEK STRUKTUR FOLDER...\n",
      "   ‚úÖ /home/muliaandiki/project/NutriPlate/preprocessing/data/Nutritionverse/train/images\n",
      "      File count: 1761\n",
      "      Sample: aug_1_dish_36_IMG_6490_jpeg.rf.f01172709b66dfe1edfb825fdcd9e47a.jpg\n",
      "   ‚úÖ /home/muliaandiki/project/NutriPlate/preprocessing/data/Nutritionverse/train/labels\n",
      "      File count: 1761\n",
      "      Sample: aug_1_dish_125_IMG_9311_jpeg.rf.26c07f4c2f2ba838f77644ab4ccb8b53.txt\n",
      "   ‚úÖ /home/muliaandiki/project/NutriPlate/preprocessing/data/Nutritionverse/valid/images\n",
      "      File count: 503\n",
      "      Sample: dish_237_IMG_3334_jpeg.rf.914b26919aedba6ce36e2a76b1cc6dd7.jpg\n",
      "   ‚úÖ /home/muliaandiki/project/NutriPlate/preprocessing/data/Nutritionverse/valid/labels\n",
      "      File count: 503\n",
      "      Sample: aug_0_dish_153_IMG_0326_jpeg.rf.2f697608a16ca484f17cf8b742a77d2f.txt\n",
      "\n",
      "3. üìÑ CEK DATA.YAML...\n",
      "   ‚úÖ File exists\n",
      "   Content:\n",
      "path: /home/muliaandiki/project/NutriPlate/preprocessing/data/Nutritionverse\n",
      "train: train/images\n",
      "val: valid/images\n",
      "test: test/images\n",
      "\n",
      "nc: 14\n",
      "names:\n",
      "  - apple\n",
      "  - sandwich\n",
      "  - bread\n",
      "  - broccoli\n",
      "  - carrot\n",
      "  - chicken\n",
      "  - beef\n",
      "  - pork\n",
      "  - seafood\n",
      "  - pizza\n",
      "  - cake\n",
      "  - tofu\n",
      "  - egg\n",
      "  - sushi\n",
      "\n",
      "\n",
      "4. üîç CEK FORMAT LABEL DETAIL...\n",
      "\n",
      "   üìÑ aug_1_dish_125_IMG_9311_jpeg.rf.26c07f4c2f2ba838f77644ab4ccb8b53.txt:\n",
      "      Total lines: 1\n",
      "      Line 1: '13 0.501787 0.514131 0.990565 0.971738'\n",
      "        Parts: 5 -> ['13', '0.501787', '0.514131', '0.990565', '0.971738']\n",
      "        Class ID: 13 (int)\n",
      "        Coordinates: [0.501787, 0.514131, 0.990565, 0.971738]\n",
      "\n",
      "   üìÑ aug_1_dish_88_IMG_8049_jpeg.rf.5b3cc7c646beb97de1147ca35bff71cf.txt:\n",
      "      Total lines: 3\n",
      "      Line 1: '13 0.565185 0.369715 0.278150 0.468459'\n",
      "        Parts: 5 -> ['13', '0.565185', '0.369715', '0.278150', '0.468459']\n",
      "        Class ID: 13 (int)\n",
      "        Coordinates: [0.565185, 0.369715, 0.27815, 0.468459]\n",
      "      Line 2: '13 0.496415 0.494589 0.984444 0.984793'\n",
      "        Parts: 5 -> ['13', '0.496415', '0.494589', '0.984444', '0.984793']\n",
      "        Class ID: 13 (int)\n",
      "        Coordinates: [0.496415, 0.494589, 0.984444, 0.984793]\n",
      "\n",
      "   üìÑ aug_1_dish_229_IMG_3055_jpeg.rf.498edb92c91abb121b338d269d83503a.txt:\n",
      "      Total lines: 5\n",
      "      Line 1: '13 0.500000 0.500000 1.000000 1.000000'\n",
      "        Parts: 5 -> ['13', '0.500000', '0.500000', '1.000000', '1.000000']\n",
      "        Class ID: 13 (int)\n",
      "        Coordinates: [0.5, 0.5, 1.0, 1.0]\n",
      "      Line 2: '13 0.390039 0.509665 0.096541 0.089857'\n",
      "        Parts: 5 -> ['13', '0.390039', '0.509665', '0.096541', '0.089857']\n",
      "        Class ID: 13 (int)\n",
      "        Coordinates: [0.390039, 0.509665, 0.096541, 0.089857]\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dataset_path = \"/home/muliaandiki/project/NutriPlate/preprocessing/data/Nutritionverse\"\n",
    "\n",
    "# 1. HAPUS SEMUA CACHE\n",
    "print(\"\\n1. üóëÔ∏è MENGHAPUS CACHE...\")\n",
    "for root, dirs, files in os.walk(dataset_path):\n",
    "    for file in files:\n",
    "        if file.endswith('.cache'):\n",
    "            cache_file = os.path.join(root, file)\n",
    "            os.remove(cache_file)\n",
    "            print(f\"   Deleted: {cache_file}\")\n",
    "\n",
    "# 2. CEK STRUKTUR FOLDER\n",
    "print(\"\\n2. üìÅ CEK STRUKTUR FOLDER...\")\n",
    "required_folders = [\n",
    "    f\"{dataset_path}/train/images\",\n",
    "    f\"{dataset_path}/train/labels\", \n",
    "    f\"{dataset_path}/valid/images\",\n",
    "    f\"{dataset_path}/valid/labels\"\n",
    "]\n",
    "\n",
    "for folder in required_folders:\n",
    "    exists = os.path.exists(folder)\n",
    "    status = \"‚úÖ\" if exists else \"‚ùå\"\n",
    "    print(f\"   {status} {folder}\")\n",
    "    \n",
    "    if exists:\n",
    "        files = os.listdir(folder)\n",
    "        print(f\"      File count: {len(files)}\")\n",
    "        if files:\n",
    "            print(f\"      Sample: {files[0]}\")\n",
    "\n",
    "# 3. CEK DATA.YAML\n",
    "print(\"\\n3. üìÑ CEK DATA.YAML...\")\n",
    "yaml_path = f\"{dataset_path}/data.yaml\"\n",
    "if os.path.exists(yaml_path):\n",
    "    with open(yaml_path, 'r') as f:\n",
    "        content = f.read()\n",
    "        print(f\"   ‚úÖ File exists\")\n",
    "        print(f\"   Content:\\n{content}\")\n",
    "else:\n",
    "    print(f\"   ‚ùå File tidak ditemukan!\")\n",
    "\n",
    "# 4. CEK FORMAT LABEL FILE DETAIL\n",
    "print(\"\\n4. üîç CEK FORMAT LABEL DETAIL...\")\n",
    "label_dir = f\"{dataset_path}/train/labels\"\n",
    "label_files = [f for f in os.listdir(label_dir) if f.endswith('.txt')][:3]  # Ambil 3 sample\n",
    "\n",
    "for label_file in label_files:\n",
    "    filepath = os.path.join(label_dir, label_file)\n",
    "    print(f\"\\n   üìÑ {label_file}:\")\n",
    "    \n",
    "    with open(filepath, 'r') as f:\n",
    "        content = f.read().strip()\n",
    "        \n",
    "    if not content:\n",
    "        print(\"      ‚ö†Ô∏è FILE KOSONG!\")\n",
    "        continue\n",
    "    \n",
    "    lines = content.split('\\n')\n",
    "    print(f\"      Total lines: {len(lines)}\")\n",
    "    \n",
    "    for i, line in enumerate(lines[:2]):  # Cek 2 baris pertama\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "            \n",
    "        print(f\"      Line {i+1}: '{line}'\")\n",
    "        parts = line.split()\n",
    "        print(f\"        Parts: {len(parts)} -> {parts}\")\n",
    "        \n",
    "        if len(parts) == 5:\n",
    "            try:\n",
    "                # Parse class_id\n",
    "                class_id = parts[0]\n",
    "                try:\n",
    "                    class_int = int(class_id)\n",
    "                    print(f\"        Class ID: {class_int} (int)\")\n",
    "                except:\n",
    "                    try:\n",
    "                        class_float = float(class_id)\n",
    "                        class_int = int(class_float)\n",
    "                        print(f\"        Class ID: {class_float} -> {class_int} (float->int)\")\n",
    "                    except:\n",
    "                        print(f\"        ‚ùå Class ID invalid: '{class_id}'\")\n",
    "                \n",
    "                # Parse coordinates\n",
    "                coords = []\n",
    "                for j, coord in enumerate(parts[1:]):\n",
    "                    try:\n",
    "                        coord_val = float(coord)\n",
    "                        coords.append(coord_val)\n",
    "                        if not (0 <= coord_val <= 1):\n",
    "                            print(f\"        ‚ö†Ô∏è Coord {j+1} out of range: {coord_val}\")\n",
    "                    except:\n",
    "                        print(f\"        ‚ùå Coord {j+1} invalid: '{coord}'\")\n",
    "                \n",
    "                print(f\"        Coordinates: {coords}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"        ‚ùå Parse error: {e}\")\n",
    "        else:\n",
    "            print(f\"        ‚ùå Expected 5 parts, got {len(parts)}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "439b3220-3450-46ab-8042-567a634ec405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5. üîß MEMPERBAIKI MASALAH UMUM...\n",
      "   Total image files: 1761\n",
      "   Total label files: 1761\n",
      "\n",
      "   üîÑ Quick fix class_id float...\n",
      "   ‚úÖ Fixed 0 label files\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# CELL 2 - FIX SIMPLE ISSUES\n",
    "print(\"5. üîß MEMPERBAIKI MASALAH UMUM...\")\n",
    "\n",
    "# A. Periksa apakah images dan labels match\n",
    "train_img_dir = f\"{dataset_path}/train/images\"\n",
    "train_lbl_dir = f\"{dataset_path}/train/labels\"\n",
    "\n",
    "img_files = {os.path.splitext(f)[0] for f in os.listdir(train_img_dir) \n",
    "             if f.endswith(('.jpg', '.jpeg', '.png'))}\n",
    "lbl_files = {os.path.splitext(f)[0] for f in os.listdir(train_lbl_dir) \n",
    "             if f.endswith('.txt')}\n",
    "\n",
    "print(f\"   Total image files: {len(img_files)}\")\n",
    "print(f\"   Total label files: {len(lbl_files)}\")\n",
    "\n",
    "# Cek mismatch\n",
    "missing_labels = img_files - lbl_files\n",
    "missing_images = lbl_files - img_files\n",
    "\n",
    "if missing_labels:\n",
    "    print(f\"   ‚ö†Ô∏è  {len(missing_labels)} images tanpa label:\")\n",
    "    for img in list(missing_labels)[:5]:\n",
    "        print(f\"      - {img}\")\n",
    "        \n",
    "if missing_images:\n",
    "    print(f\"   ‚ö†Ô∏è  {len(missing_images)} labels tanpa image:\")\n",
    "    for lbl in list(missing_images)[:5]:\n",
    "        print(f\"      - {lbl}\")\n",
    "\n",
    "# B. Quick fix untuk class_id float\n",
    "print(f\"\\n   üîÑ Quick fix class_id float...\")\n",
    "fixed_count = 0\n",
    "\n",
    "for lbl_file in os.listdir(train_lbl_dir):\n",
    "    if lbl_file.endswith('.txt'):\n",
    "        filepath = os.path.join(train_lbl_dir, lbl_file)\n",
    "        \n",
    "        with open(filepath, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "        \n",
    "        new_lines = []\n",
    "        changed = False\n",
    "        \n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "                \n",
    "            parts = line.split()\n",
    "            if len(parts) == 5:\n",
    "                # Fix class_id\n",
    "                try:\n",
    "                    class_str = parts[0]\n",
    "                    # Coba parse sebagai float lalu ke int\n",
    "                    try:\n",
    "                        class_id = int(float(class_str))\n",
    "                    except:\n",
    "                        class_id = 0  # default\n",
    "                    \n",
    "                    # Buat line baru\n",
    "                    new_line = f\"{class_id} {parts[1]} {parts[2]} {parts[3]} {parts[4]}\"\n",
    "                    if new_line != line:\n",
    "                        changed = True\n",
    "                    new_lines.append(new_line)\n",
    "                except:\n",
    "                    new_lines.append(line)  # keep original if error\n",
    "            else:\n",
    "                new_lines.append(line)  # keep as is\n",
    "        \n",
    "        if changed and new_lines:\n",
    "            with open(filepath, 'w') as f:\n",
    "                f.write(\"\\n\".join(new_lines))\n",
    "            fixed_count += 1\n",
    "\n",
    "print(f\"   ‚úÖ Fixed {fixed_count} label files\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0a5dbae8-d2d1-4481-bd1d-7211984bdec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6. üöÄ COBA TRAINING DENGAN FIX ULTIMATE...\n",
      "\n",
      "   ‚öôÔ∏è  Setting training:\n",
      "      - Model: yolov8n.pt (kecil dulu)\n",
      "      - Epochs: 2\n",
      "      - Batch: 2\n",
      "      - Imgsz: 320\n",
      "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt to 'yolov8n.pt': 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6.2MB 324.0KB/s 19.7s.7s<0.1ss.1s\n",
      "New https://pypi.org/project/ultralytics/8.3.240 available üòÉ Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.236 üöÄ Python-3.12.3 torch-2.7.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3050 6GB Laptop GPU, 5804MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=False, augment=False, auto_augment=randaugment, batch=2, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/home/muliaandiki/project/NutriPlate/preprocessing/data/Nutritionverse/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=2, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=320, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=ultimate_test, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=0, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=runs/debug, rect=False, resume=False, retina_masks=False, save=False, save_conf=False, save_crop=False, save_dir=/home/muliaandiki/project/NutriPlate/preprocessing/runs/debug/ultimate_test, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=1, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=14\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    754042  ultralytics.nn.modules.head.Detect           [14, [64, 128, 256]]          \n",
      "Model summary: 129 layers, 3,013,578 parameters, 3,013,562 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 2834.9¬±2469.5 MB/s, size: 4128.5 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/muliaandiki/project/NutriPlate/preprocessing/data/Nutritionverse/train/labels... 1761 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1761/1761 4.2Kit/s 0.4s0.0s\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /home/muliaandiki/project/NutriPlate/preprocessing/data/Nutritionverse/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 557.4¬±257.2 MB/s, size: 5337.9 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /home/muliaandiki/project/NutriPlate/preprocessing/data/Nutritionverse/valid/labels... 503 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 503/503 3.9Kit/s 0.1s0.1s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /home/muliaandiki/project/NutriPlate/preprocessing/data/Nutritionverse/valid/labels.cache\n",
      "Plotting labels to /home/muliaandiki/project/NutriPlate/preprocessing/runs/debug/ultimate_test/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000556, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 320 train, 320 val\n",
      "Using 1 dataloader workers\n",
      "Logging results to \u001b[1m/home/muliaandiki/project/NutriPlate/preprocessing/runs/debug/ultimate_test\u001b[0m\n",
      "Starting training for 2 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K        1/2      1.17G     0.7249      2.255      1.154          6        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 881/881 9.8it/s 1:300<0.1ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 126/126 9.8it/s 12.8s<0.1s\n",
      "                   all        503       1069      0.743      0.684      0.761      0.677\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K        2/2      1.17G     0.5658      1.201      1.083          4        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 881/881 9.9it/s 1:29<0.2sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 126/126 9.9it/s 12.7s0.1ss\n",
      "                   all        503       1069      0.676      0.777       0.74      0.666\n",
      "\n",
      "2 epochs completed in 0.057 hours.\n",
      "Optimizer stripped from /home/muliaandiki/project/NutriPlate/preprocessing/runs/debug/ultimate_test/weights/last.pt, 6.2MB\n",
      "\n",
      "üéâüéâüéâ BERHASIL! üéâüéâüéâ\n",
      "Dataset kamu sudah FIX dan siap untuk training full!\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# CELL 3 - TRY ULTIMATE FIX\n",
    "print(\"6. üöÄ COBA TRAINING DENGAN FIX ULTIMATE...\")\n",
    "\n",
    "from ultralytics import YOLO\n",
    "import torch\n",
    "\n",
    "# HAPUS CACHE LAGI\n",
    "cache_file = f\"{dataset_path}/train/labels.cache\"\n",
    "if os.path.exists(cache_file):\n",
    "    os.remove(cache_file)\n",
    "    print(f\"   üóëÔ∏è  Cache dihapus lagi: {cache_file}\")\n",
    "\n",
    "# COBA DENGAN SETTING SANGAT SEDERHANA\n",
    "print(\"\\n   ‚öôÔ∏è  Setting training:\")\n",
    "print(\"      - Model: yolov8n.pt (kecil dulu)\")\n",
    "print(\"      - Epochs: 2\")\n",
    "print(\"      - Batch: 2\")\n",
    "print(\"      - Imgsz: 320\")\n",
    "\n",
    "try:\n",
    "    model = YOLO('yolov8n.pt')\n",
    "    \n",
    "    results = model.train(\n",
    "        data=f\"{dataset_path}/data.yaml\",\n",
    "        epochs=2,\n",
    "        imgsz=320,\n",
    "        batch=2,\n",
    "        device=0 if torch.cuda.is_available() else 'cpu',\n",
    "        workers=1,  # Minimal workers untuk debugging\n",
    "        verbose=True,\n",
    "        project=\"runs/debug\",\n",
    "        name=\"ultimate_test\",\n",
    "        exist_ok=True,\n",
    "        amp=False,  # Nonaktifkan AMP\n",
    "        lr0=0.01,   # Learning rate default\n",
    "        patience=0,  # No early stopping\n",
    "        save=False,  # Tidak save model dulu\n",
    "        cache=False, # Tidak pakai cache\n",
    "    )\n",
    "    \n",
    "    print(\"\\nüéâüéâüéâ BERHASIL! üéâüéâüéâ\")\n",
    "    print(\"Dataset kamu sudah FIX dan siap untuk training full!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå MASIH ERROR: {type(e).__name__}\")\n",
    "    print(f\"   Message: {str(e)}\")\n",
    "    \n",
    "    # EXTREME DEBUGGING\n",
    "    print(\"\\nüîß EXTREME DEBUGGING...\")\n",
    "    \n",
    "    # Coba buka satu gambar\n",
    "    import cv2\n",
    "    sample_img = os.path.join(dataset_path, \"train\", \"images\", os.listdir(f\"{dataset_path}/train/images\")[0])\n",
    "    print(f\"\\n   Coba buka gambar: {sample_img}\")\n",
    "    try:\n",
    "        img = cv2.imread(sample_img)\n",
    "        if img is not None:\n",
    "            print(f\"   ‚úÖ Gambar bisa dibuka: Shape {img.shape}\")\n",
    "        else:\n",
    "            print(f\"   ‚ùå Gambar tidak bisa dibuka!\")\n",
    "    except Exception as img_error:\n",
    "        print(f\"   ‚ùå Error buka gambar: {img_error}\")\n",
    "    \n",
    "    # Coba manual dataset check\n",
    "    print(f\"\\n   Coba check_det_dataset manual...\")\n",
    "    try:\n",
    "        from ultralytics.data.utils import check_det_dataset\n",
    "        data_info = check_det_dataset(f\"{dataset_path}/data.yaml\")\n",
    "        print(f\"   ‚úÖ check_det_dataset berhasil\")\n",
    "    except Exception as check_error:\n",
    "        print(f\"   ‚ùå check_det_dataset error: {check_error}\")\n",
    "        \n",
    "    # SOLUSI RADICAL\n",
    "    print(f\"\\nüí° SOLUSI RADICAL:\")\n",
    "    print(f\"   1. Copy semua gambar ke format .jpg\")\n",
    "    print(f\"   2. Gunakan yolov5 format\")\n",
    "    print(f\"   3. Buat dataset baru dari scratch\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "cd1e76e3-0a61-4f31-800a-4709e9c85f4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7. üöÄ JIKA TEST BERHASIL, LANJUT TRAINING FULL...\n",
      "\n",
      "‚úÖ Test training berhasil ditemukan di: runs/debug/ultimate_test\n",
      "üóëÔ∏è  Hapus cache: /home/muliaandiki/project/NutriPlate/preprocessing/data/Nutritionverse/train/labels.cache\n",
      "üóëÔ∏è  Hapus cache: /home/muliaandiki/project/NutriPlate/preprocessing/data/Nutritionverse/valid/labels.cache\n",
      "\n",
      "üöÄ Memulai training FULL dengan yolov8l.pt\n",
      "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8l.pt to 'yolov8l.pt': 62% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 52.0/83.7MB 6.9MB/s 7.5s<4.6ss4s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[64]\u001b[39m\u001b[32m, line 24\u001b[39m\n\u001b[32m     21\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33müöÄ Memulai training FULL dengan yolov8l.pt\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m     model = \u001b[43mYOLO\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43myolov8l.pt\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     26\u001b[39m     model.train(\n\u001b[32m     27\u001b[39m         data=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/data.yaml\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     28\u001b[39m         epochs=\u001b[32m100\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     52\u001b[39m         pretrained=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m     53\u001b[39m     )\n\u001b[32m     55\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33müéâüéâüéâ TRAINING FULL SELESAI! üéâüéâüéâ\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/project/NutriPlate/preprocessing/yolov_env/lib/python3.12/site-packages/ultralytics/models/yolo/model.py:76\u001b[39m, in \u001b[36mYOLO.__init__\u001b[39m\u001b[34m(self, model, task, verbose)\u001b[39m\n\u001b[32m     73\u001b[39m     \u001b[38;5;28mself\u001b[39m.\u001b[34m__dict__\u001b[39m = new_instance.\u001b[34m__dict__\u001b[39m\n\u001b[32m     74\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     75\u001b[39m     \u001b[38;5;66;03m# Continue with default YOLO initialization\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     77\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.model, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mRTDETR\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.model.model[-\u001b[32m1\u001b[39m]._get_name():  \u001b[38;5;66;03m# if RTDETR head\u001b[39;00m\n\u001b[32m     78\u001b[39m         \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01multralytics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RTDETR\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/project/NutriPlate/preprocessing/yolov_env/lib/python3.12/site-packages/ultralytics/engine/model.py:144\u001b[39m, in \u001b[36mModel.__init__\u001b[39m\u001b[34m(self, model, task, verbose)\u001b[39m\n\u001b[32m    142\u001b[39m     \u001b[38;5;28mself\u001b[39m._new(model, task=task, verbose=verbose)\n\u001b[32m    143\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m144\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    146\u001b[39m \u001b[38;5;66;03m# Delete super().training for accessing self.model.training\u001b[39;00m\n\u001b[32m    147\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m.training\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/project/NutriPlate/preprocessing/yolov_env/lib/python3.12/site-packages/ultralytics/engine/model.py:283\u001b[39m, in \u001b[36mModel._load\u001b[39m\u001b[34m(self, weights, task)\u001b[39m\n\u001b[32m    280\u001b[39m weights = checks.check_model_file_from_stem(weights)  \u001b[38;5;66;03m# add suffix, i.e. yolo11n -> yolo11n.pt\u001b[39;00m\n\u001b[32m    282\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(weights).rpartition(\u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m)[-\u001b[32m1\u001b[39m] == \u001b[33m\"\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m283\u001b[39m     \u001b[38;5;28mself\u001b[39m.model, \u001b[38;5;28mself\u001b[39m.ckpt = \u001b[43mload_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    284\u001b[39m     \u001b[38;5;28mself\u001b[39m.task = \u001b[38;5;28mself\u001b[39m.model.task\n\u001b[32m    285\u001b[39m     \u001b[38;5;28mself\u001b[39m.overrides = \u001b[38;5;28mself\u001b[39m.model.args = \u001b[38;5;28mself\u001b[39m._reset_ckpt_args(\u001b[38;5;28mself\u001b[39m.model.args)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/project/NutriPlate/preprocessing/yolov_env/lib/python3.12/site-packages/ultralytics/nn/tasks.py:1461\u001b[39m, in \u001b[36mload_checkpoint\u001b[39m\u001b[34m(weight, device, inplace, fuse)\u001b[39m\n\u001b[32m   1448\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload_checkpoint\u001b[39m(weight, device=\u001b[38;5;28;01mNone\u001b[39;00m, inplace=\u001b[38;5;28;01mTrue\u001b[39;00m, fuse=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m   1449\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Load a single model weights.\u001b[39;00m\n\u001b[32m   1450\u001b[39m \n\u001b[32m   1451\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1459\u001b[39m \u001b[33;03m        ckpt (dict): Model checkpoint dictionary.\u001b[39;00m\n\u001b[32m   1460\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1461\u001b[39m     ckpt, weight = \u001b[43mtorch_safe_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# load ckpt\u001b[39;00m\n\u001b[32m   1462\u001b[39m     args = {**DEFAULT_CFG_DICT, **(ckpt.get(\u001b[33m\"\u001b[39m\u001b[33mtrain_args\u001b[39m\u001b[33m\"\u001b[39m, {}))}  \u001b[38;5;66;03m# combine model and default args, preferring model args\u001b[39;00m\n\u001b[32m   1463\u001b[39m     model = (ckpt.get(\u001b[33m\"\u001b[39m\u001b[33mema\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m ckpt[\u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m]).float()  \u001b[38;5;66;03m# FP32 model\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/project/NutriPlate/preprocessing/yolov_env/lib/python3.12/site-packages/ultralytics/nn/tasks.py:1387\u001b[39m, in \u001b[36mtorch_safe_load\u001b[39m\u001b[34m(weight, safe_only)\u001b[39m\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01multralytics\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdownloads\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m attempt_download_asset\n\u001b[32m   1386\u001b[39m check_suffix(file=weight, suffix=\u001b[33m\"\u001b[39m\u001b[33m.pt\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1387\u001b[39m file = \u001b[43mattempt_download_asset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# search online if missing locally\u001b[39;00m\n\u001b[32m   1388\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1389\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m temporary_modules(\n\u001b[32m   1390\u001b[39m         modules={\n\u001b[32m   1391\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33multralytics.yolo.utils\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33multralytics.utils\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1399\u001b[39m         },\n\u001b[32m   1400\u001b[39m     ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/project/NutriPlate/preprocessing/yolov_env/lib/python3.12/site-packages/ultralytics/utils/downloads.py:467\u001b[39m, in \u001b[36mattempt_download_asset\u001b[39m\u001b[34m(file, repo, release, **kwargs)\u001b[39m\n\u001b[32m    464\u001b[39m         safe_download(url=url, file=file, min_bytes=\u001b[32m1e5\u001b[39m, **kwargs)\n\u001b[32m    466\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m repo == GITHUB_ASSETS_REPO \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m GITHUB_ASSETS_NAMES:\n\u001b[32m--> \u001b[39m\u001b[32m467\u001b[39m     \u001b[43msafe_download\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdownload_url\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mrelease\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mname\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_bytes\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1e5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    469\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    470\u001b[39m     tag, assets = get_github_assets(repo, release)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/project/NutriPlate/preprocessing/yolov_env/lib/python3.12/site-packages/ultralytics/utils/downloads.py:347\u001b[39m, in \u001b[36msafe_download\u001b[39m\u001b[34m(url, file, dir, unzip, delete, curl, retry, min_bytes, exist_ok, progress)\u001b[39m\n\u001b[32m    345\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(f, \u001b[33m\"\u001b[39m\u001b[33mwb\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f_opened:\n\u001b[32m    346\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m347\u001b[39m         data = \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuffer_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    348\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data:\n\u001b[32m    349\u001b[39m             \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/http/client.py:479\u001b[39m, in \u001b[36mHTTPResponse.read\u001b[39m\u001b[34m(self, amt)\u001b[39m\n\u001b[32m    476\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.length \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt > \u001b[38;5;28mself\u001b[39m.length:\n\u001b[32m    477\u001b[39m     \u001b[38;5;66;03m# clip the read to the \"end of response\"\u001b[39;00m\n\u001b[32m    478\u001b[39m     amt = \u001b[38;5;28mself\u001b[39m.length\n\u001b[32m--> \u001b[39m\u001b[32m479\u001b[39m s = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    480\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m s \u001b[38;5;129;01mand\u001b[39;00m amt:\n\u001b[32m    481\u001b[39m     \u001b[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[32m    482\u001b[39m     \u001b[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[32m    483\u001b[39m     \u001b[38;5;28mself\u001b[39m._close_conn()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/socket.py:707\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    705\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    706\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m707\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    708\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[32m    709\u001b[39m         \u001b[38;5;28mself\u001b[39m._timeout_occurred = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/ssl.py:1252\u001b[39m, in \u001b[36mSSLSocket.recv_into\u001b[39m\u001b[34m(self, buffer, nbytes, flags)\u001b[39m\n\u001b[32m   1248\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1249\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1250\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1251\u001b[39m           \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1252\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1253\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1254\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv_into(buffer, nbytes, flags)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/ssl.py:1104\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1102\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1103\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1104\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1105\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1106\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# CELL 4 - JIKA BERHASIL, TRAINING FULL\n",
    "print(\"7. üöÄ JIKA TEST BERHASIL, LANJUT TRAINING FULL...\")\n",
    "\n",
    "# Cek apakah test berhasil\n",
    "test_dir = \"runs/debug/ultimate_test\"\n",
    "if os.path.exists(test_dir):\n",
    "    print(f\"\\n‚úÖ Test training berhasil ditemukan di: {test_dir}\")\n",
    "    \n",
    "    # Hapus cache untuk training full\n",
    "    cache_files = [\n",
    "        f\"{dataset_path}/train/labels.cache\",\n",
    "        f\"{dataset_path}/valid/labels.cache\"\n",
    "    ]\n",
    "    \n",
    "    for cf in cache_files:\n",
    "        if os.path.exists(cf):\n",
    "            os.remove(cf)\n",
    "            print(f\"üóëÔ∏è  Hapus cache: {cf}\")\n",
    "    \n",
    "    # Training full dengan model besar\n",
    "    print(f\"\\nüöÄ Memulai training FULL dengan yolov8l.pt\")\n",
    "    \n",
    "    try:\n",
    "        model = YOLO('yolov8l.pt')\n",
    "        \n",
    "        model.train(\n",
    "            data=f\"{dataset_path}/data.yaml\",\n",
    "            epochs=100,\n",
    "            imgsz=640,\n",
    "            batch=4,  # Adjust sesuai GPU memory\n",
    "            device=0,\n",
    "            workers=4,\n",
    "            verbose=True,\n",
    "            project=\"runs/train\",\n",
    "            name=\"nutritionverse_full\",\n",
    "            exist_ok=True,\n",
    "            amp=True,\n",
    "            optimizer=\"AdamW\",\n",
    "            lr0=0.001,\n",
    "            lrf=0.01,\n",
    "            momentum=0.937,\n",
    "            weight_decay=0.0005,\n",
    "            warmup_epochs=3,\n",
    "            warmup_momentum=0.8,\n",
    "            box=7.5,\n",
    "            cls=0.5,\n",
    "            dfl=1.5,\n",
    "            close_mosaic=10,\n",
    "            resume=False,\n",
    "            save=True,\n",
    "            save_period=10,\n",
    "            pretrained=True,\n",
    "        )\n",
    "        \n",
    "        print(f\"\\nüéâüéâüéâ TRAINING FULL SELESAI! üéâüéâüéâ\")\n",
    "        \n",
    "    except Exception as full_error:\n",
    "        print(f\"\\n‚ùå Error training full: {full_error}\")\n",
    "        \n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è  Test belum berhasil, selesaikan debugging dulu\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
